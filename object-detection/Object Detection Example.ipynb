{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "273aaf5c-80ea-4d8a-9bbc-721b25afe07e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Object Detection: Moving towards a production pipeline\n",
    "\n",
    "This example illustrates a common Object Detection use case using [Pachyderm](https://www.pachyderm.com/), [Lightning Flash](https://lightning-flash.readthedocs.io/en/latest/), and [Label Studio](https://labelstud.io/). \n",
    "\n",
    "<p align=\"center\">\n",
    "\t<img src='images/diagram.png' width='500' title='Pachyderm'>\n",
    "</p>\n",
    "\n",
    "This demo mimics the object detection [example from Lightning Flash](https://lightning-flash.readthedocs.io/en/stable/reference/object_detection.html#example). We extend the example to predict on new data that can be used to produce predictions for the [Pachyderm Label Studio integration](https://github.com/pachyderm/label-studio) to refine and improve your training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d2fbab-141d-47e9-9eb4-977c7281e022",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 1: Upload Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d55c01-6d43-4c13-b038-fdc5c1927496",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/zhiqwang/yolov5-rt-stack/releases/download/v0.3.0/coco128.zip\n",
    "!unzip coco128.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2588bf-60a1-4862-a8c4-14635d587840",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pachctl create repo coco128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8cebfc-484b-4518-88b1-58a4785f1561",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pachctl put file -r coco128@master:/coco128/ -f coco128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2905b7c2-efab-4f76-b576-063f84b7e7e2",
   "metadata": {},
   "source": [
    "## Step 2: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae76fe7f-0f98-4bbe-97db-800f927cb0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pachctl create pipeline -f pachyderm/model.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b328068-24e9-4663-a87b-a1ff9d823694",
   "metadata": {},
   "source": [
    "## Step 3: Predict on Inference Data\n",
    "Our `predictions` pipeline uses combines our `inference_images` data repo with the output of our model pipeline. \n",
    "\n",
    "In this example, we cross these two inputs via the spec: \n",
    "```yaml\n",
    "input:\n",
    "  cross:\n",
    "  - pfs:\n",
    "      repo: inference_images\n",
    "      glob: \"/*\"\n",
    "  - pfs:\n",
    "      repo: model\n",
    "      glob: \"/\"\n",
    "```\n",
    "\n",
    "This means that each time an image is added or changed in `inference_images` it will be processed independently. But whenever our model is retrained, we will reprocess all of our inference_images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2d1cf6-b314-4ed9-a141-84993f60bb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add inference data\n",
    "!pachctl create repo inference_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48ee0ae-1fbf-4dd7-b7d0-465d73405a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy prediction pipeline\n",
    "!pachctl create pipeline -f pachyderm/predictions.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0cc552-6405-4b40-93ac-ee1530a9da1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data to be predicted on (pipelines run automatically)\n",
    "!pachctl put file -r inference_images@master:/dog1.jpeg -f images/dog1.jpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269f7aab-f263-4ba1-ac28-cb9bf033ebdf",
   "metadata": {},
   "source": [
    "We'll now deploy one more pipeline that will let us visualize the bounding boxes our model predicted. Everything is versioned, so if our model changes, then we'll be able to see the difference in our bounding boxs as our model changes over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77217c65-b891-4aa0-b8c1-7b61d9b9238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pachctl create pipeline -f pachyderm/bbox.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4628434a-9ac0-4f7c-9ddd-24db4a6cef7e",
   "metadata": {},
   "source": [
    "## Step 4: Edit Predictions in Label Studio\n",
    "In order to load the predictions into Label Studio, follow the [Label Studio integration](https://github.com/pachyderm/examples/tree/master/label-studio) to run the server locally using our pre-built Docker container, passing it your Pachyderm config. \n",
    "\n",
    "Once it is running, continue with the steps below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e25809-f954-46bd-831b-258bc8ddd442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels repo to push our annotations to\n",
    "!pachctl create repo labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7907290f-dbef-40fc-a959-6fd975830c68",
   "metadata": {},
   "source": [
    "1. Create an Object Detection with Bounding Boxes project in Label Studio. \n",
    "2. Paste in the class list from `./classes_raw.txt`\n",
    "3. Configure Label Studio's Cloud Storage to:\n",
    "**Source Storage**: `inference_images@master`, `predictions@master` (make sure to sync inference_images first so the image files exist for the predictions when they're imported)\n",
    "\n",
    "<p align=\"center\">\n",
    "\t<img src='images/inference_images_config.png' width='600' title='Pachyderm'>\n",
    "</p>\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "\t<img src='images/predictions_config.png' width='600' title='Pachyderm'>\n",
    "</p>\n",
    "\n",
    "Note: We need to tread every object as a source file with `inference_images` but not `predictions`.\n",
    "\n",
    "**Target Storage**: `labels`\n",
    "\n",
    "After configuring and syncing everything, your Cloud Storage settings should look like this: \n",
    "\n",
    "<p align=\"center\">\n",
    "\t<img src='images/ls_cloud_storage_config.png' width='600' title='Pachyderm'>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181331ed-498d-4e75-8ecd-e580cfc10bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the classes available\n",
    "#!cat classes_raw.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a812910e-f282-4baa-a909-49d454aa13b6",
   "metadata": {},
   "source": [
    "Now you can edit the labels for your data, and once you're satisfied with your progress, sync your labels to Pachyderm with the `Sync Storage` option on your `labels` data repository in the Cloud Storage settings. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99025e62-4524-4813-b709-d78fba20c491",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3731a3-fd86-4624-9cec-564cf2ceec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pachctl delete pipeline predictions\n",
    "!pachctl delete pipeline model\n",
    "!pachctl delete repo labels\n",
    "!pachctl delete repo inference_images\n",
    "!pachctl delete repo coco128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249ff9f4-7d89-4354-987d-aa14ac8c752f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
